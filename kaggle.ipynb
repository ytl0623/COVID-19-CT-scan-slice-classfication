{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Colab使用說明，請先點選左上角執行階段=>變更執行階段類型=>硬體加速器選擇GPU，接著回到頁面點選右上角的連線，接著執行下方儲存格"],"metadata":{"id":"F53O3WKpt2SX"}},{"cell_type":"markdown","source":[">醫學影像專題 \n","資料集來源:https://www.kaggle.com/datasets/maedemaftouni/large-covid19-ct-slice-dataset"],"metadata":{"id":"iqCP6cEZ00Qe"}},{"cell_type":"markdown","source":["# kaggle\n","\n","> 在kaggle註冊後，點=>自己頭像=>account=>Create New API Token按下去會有一個kaggle_json檔案下載\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"I2iPSiNDHNEL"}},{"cell_type":"markdown","source":["\n","\n","> 把剛才的json檔案上傳\n","\n"],"metadata":{"id":"Uk4CzoLWIcD7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLywU74FGuDU"},"outputs":[],"source":["! pip install -q kaggle\n","from google.colab import files\n","files.upload()"]},{"cell_type":"code","source":["! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"AS--Aa6vHJzU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> 下載zip檔案\n","\n"],"metadata":{"id":"4AKV6Ez-Mgto"}},{"cell_type":"code","source":["! kaggle datasets download -d maedemaftouni/large-covid19-ct-slice-dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5993torgHd1c","outputId":"7596335e-20f0-4d12-c9ea-966bf9a1e172"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading large-covid19-ct-slice-dataset.zip to /content\n","100% 2.06G/2.06G [01:34<00:00, 23.7MB/s]\n","100% 2.06G/2.06G [01:34<00:00, 23.4MB/s]\n"]}]},{"cell_type":"markdown","source":["\n","\n","> 創建資料夾input，並解壓縮檔案至input\n","\n"],"metadata":{"id":"WBQTREwZMn-r"}},{"cell_type":"code","source":["! mkdir input"],"metadata":{"id":"cGlesRjwHs1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip large-covid19-ct-slice-dataset.zip -d input"],"metadata":{"id":"oybKZvGdHwrU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset(除了train、validation的比例可更動外，其餘部分不要更動)\n","\n","---\n","\n","\n","**非常重要**，因為資料集給的是一個病患好幾張切片，所以在分資料集時\"不能\"直接以切片為單位分，而是要以病患為單位分\n"],"metadata":{"id":"nbV1Zu1oZjxi"}},{"cell_type":"markdown","source":["病患人數為604、464，資料集比例分為6:2:2"],"metadata":{"id":"OS7ilRuH_DLr"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset\n","from pathlib import Path\n","from PIL import Image\n","import random\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import copy\n","import time\n","import os\n","import torchvision.models as models\n","from tqdm import tqdm\n","from typing import Literal\n","from functools import reduce\n","import csv\n","\n","def load_patients(csv_path, data_dir_path):\n","    patients = {}\n","    with open(csv_path, encoding= 'unicode_escape') as csvFile : \n","        csvDictReader = csv.DictReader(csvFile) \n","        for row in csvDictReader:\n","            pid = row[\"Patient ID\"]\n","            if patients.get(pid) is None:\n","                patients[pid] = []\n","            patients[pid].append(os.path.join(data_dir_path, row[\"File name\"]))\n","\n","    return [patient for patient in patients.values()]\n","\n","def percent_list_slice(x, start=0., end=1.):\n","    return x[int(len(x)*start):int(len(x)*end)]\n","\n","class CovidCT(Dataset):\n","    def __init__(self,\n","                 data_root,\n","                 mode: Literal[\"train\", \"valid\", \"test\"] = \"train\",\n","                 transform=None):\n","        if mode == \"train\":\n","            start, end = 0.0, 0.6\n","        elif mode == \"valid\":\n","            start, end = 0.6, 0.8\n","        elif mode == \"test\":\n","            start, end = 0.8, 1.0\n","\n","        normal_patients = load_patients(\n","            os.path.join(data_root, \"meta_data_normal.csv\"),\n","            os.path.join(data_root, \"curated_data/curated_data/1NonCOVID\"))\n","        normal_patients = percent_list_slice(normal_patients, start, end)\n","        normal_file_paths = reduce(lambda a, b: a+b, normal_patients)\n","        \n","        covid_patients = load_patients(\n","            os.path.join(data_root, \"meta_data_covid.csv\"),\n","            os.path.join(data_root, \"curated_data/curated_data/2COVID\"))\n","        covid_patients = percent_list_slice(covid_patients, start, end)\n","        covid_file_paths = reduce(lambda a, b: a+b, covid_patients)\n","\n","        self.file_paths = normal_file_paths + covid_file_paths\n","        self.labels = [0]*len(normal_file_paths) + [1]*len(covid_file_paths)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.file_paths[index]).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, self.labels[index]"],"metadata":{"id":"xs-n5TLUcXR5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train\n","\n","\n","> 請注意，由於code為了方便檢視，將資料儲存在最外層(意思就是colab down之後，資料就會不見，請記得更改儲存路徑)\n","\n","\n","---\n","\n","\n","> 在這裡可以發揮您的創造力去改變模型以及任何超參數\n","\n","\n","\n"],"metadata":{"id":"2lOjUBQiXo4r"}},{"cell_type":"code","source":["CUDA_DEVICES = 0\n","init_lr = 0.01\n","\n","# Save model every 5 epochs\n","checkpoint_interval = 5\n","if not os.path.isdir('./Checkpoint/'):\n","    os.mkdir('./Checkpoint/')\n","\n","\n","# Setting learning rate operation\n","def adjust_lr(optimizer, epoch):\n","    # 1/10 learning rate every 5 epochs\n","    lr = init_lr * (0.1 ** (epoch // 5))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","def train():\n","    # If out of memory , adjusting the batch size smaller\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","    trainset = CovidCT(\"/content/input/\", \"train\", data_transform)\n","    train_dl = DataLoader(trainset, batch_size=9, shuffle=True, num_workers=3)\n","    validset = CovidCT(\"/content/input/\", \"valid\", data_transform)\n","    valid_dl = DataLoader(validset, batch_size=9, shuffle=False, num_workers=3)\n","    classes = ['1NonCOVID','2COVID']\n","    \n","    model=models.resnet18(pretrained=True)\n","    model.fc=nn.Linear(in_features=512, out_features=2, bias=True) #如果要使用預訓練模型，記得修改最後一層輸出的class數量\n","    print(model)\n","    print(\"==========\")\n","\n","    total = sum([param.nelement() for param in model.parameters()])\n","    print(\"Number of parameter: %.2fM\" % (total/1e6))\n","    model = model.cuda(CUDA_DEVICES)\n","\n","    model.train()\n","\n","    best_model_params = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    # Training epochs\n","    num_epochs = 5 \n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Optimizer setting\n","    optimizer = torch.optim.SGD(params=model.parameters(), lr=init_lr, momentum=0.9)\n","\n","    # Log \n","    with open('TrainingAccuracy.txt','w') as fAcc:\n","        print('Accuracy\\n', file = fAcc)\n","    with open('TrainingLoss.txt','w') as fLoss:\n","        print('Loss\\n', file = fLoss)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        localtime = time.asctime( time.localtime(time.time()) )\n","        print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime))\n","        print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime)))\n","\n","        training_loss = 0.0\n","        training_corrects = 0\n","        adjust_lr(optimizer, epoch)\n","\n","        for i, (inputs, labels) in (enumerate(tqdm(train_dl))):\n","\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs.data, 1)\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            training_loss += float(loss.item() * inputs.size(0))\n","            training_corrects += torch.sum(preds == labels.data).item()\n","\n","        training_loss = training_loss / len(trainset)\n","        training_acc = training_corrects /len(trainset)\n","        print('\\n Training loss: {:.4f}\\taccuracy: {:.4f}\\n'.format(training_loss,training_acc))\n","        \n","\n","        # Check best accuracy model ( but not the best on test )\n","        if training_acc > best_acc:\n","            best_acc = training_acc\n","            best_model_params = copy.deepcopy(model.state_dict())\n","\n","\n","        with open('TrainingAccuracy.txt','a') as fAcc:\n","            print('{:.4f} '.format(training_acc), file = fAcc)\n","        with open('TrainingLoss.txt','a') as fLoss:\n","            print('{:.4f} '.format(training_loss), file = fLoss)\n","        if (epoch + 1) % checkpoint_interval == 0:\n","            torch.save(model, './Checkpoint/model-epoch-{:d}-train.pth'.format(epoch + 1))\n","\n","        model = model.cuda(CUDA_DEVICES)\n","        model.eval()\n","        total_correct = 0\n","        total = 0\n","        class_correct = list(0. for i in enumerate(classes))\n","        class_total = list(0. for i in enumerate(classes))\n","\n","        with torch.no_grad():\n","            for inputs, labels in tqdm(valid_dl):\n","                inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","                labels = Variable(labels.cuda(CUDA_DEVICES))\n","                outputs = model(inputs)\n","                \n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                total_correct += (predicted == labels).sum().item()\n","                c = (predicted == labels).squeeze()\n","                \n","\n","                for i in range(labels.size(0)):\n","                    label = labels[i]\n","                    class_correct[label] += c[i].item()\n","                    class_total[label] += 1\n","\n","            for i, c in enumerate(classes):\n","              if(class_total[i]==0):\n","                print('Accuracy of %5s : %8.4f %%' % (\n","                c, 100 * 0))\n","              else:\n","                print('Accuracy of %5s : %8.4f %%' % (\n","                c, 100 * class_correct[i] / class_total[i]))\n","\n","            # Accuracy\n","            print('\\nAccuracy on the ALL val images: %.4f %%'\n","              % (100 * total_correct / total))\n","            \n","    # Save best training/valid accuracy model ( not the best on test )\n","    model.load_state_dict(best_model_params)\n","    best_model_name = './Checkpoint/model-{:.2f}-best_train_acc.pth'.format(best_acc)\n","    torch.save(model, best_model_name)\n","    print(\"Best model name : \" + best_model_name)\n","if __name__ == '__main__':\n","    train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8fA6SyVKIiL","outputId":"61271655-f8e6-4556-f4f3-8baab1a68084"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=3, bias=True)\n",")\n","==========\n","Number of parameter: 11.18M\n","Epoch: 1/5 --- < Starting Time : Mon Mar 13 11:36:59 2023 >\n","-----------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 709/709 [00:45<00:00, 15.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training loss: 0.8957\taccuracy: 0.6312\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 286/286 [00:14<00:00, 19.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  95.8264 %\n","Accuracy of 2COVID :  94.6667 %\n","\n","Accuracy on the ALL val images: 95.7588 %\n","Epoch: 2/5 --- < Starting Time : Mon Mar 13 11:37:59 2023 >\n","-----------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 709/709 [00:45<00:00, 15.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training loss: 0.5905\taccuracy: 0.7184\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 286/286 [00:14<00:00, 20.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  99.6281 %\n","Accuracy of 2COVID :  99.3333 %\n","\n","Accuracy on the ALL val images: 99.6109 %\n","Epoch: 3/5 --- < Starting Time : Mon Mar 13 11:38:58 2023 >\n","-----------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 709/709 [00:46<00:00, 15.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training loss: 0.4899\taccuracy: 0.7780\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 286/286 [00:14<00:00, 19.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  97.2314 %\n","Accuracy of 2COVID :  98.0000 %\n","\n","Accuracy on the ALL val images: 97.2763 %\n","Epoch: 4/5 --- < Starting Time : Mon Mar 13 11:39:59 2023 >\n","-----------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 709/709 [00:45<00:00, 15.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training loss: 0.3938\taccuracy: 0.8194\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 286/286 [00:14<00:00, 19.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  99.6281 %\n","Accuracy of 2COVID :  93.3333 %\n","\n","Accuracy on the ALL val images: 99.2607 %\n","Epoch: 5/5 --- < Starting Time : Mon Mar 13 11:40:59 2023 >\n","-----------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 709/709 [00:45<00:00, 15.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training loss: 0.3807\taccuracy: 0.8313\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 286/286 [00:14<00:00, 19.81it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  96.2397 %\n","Accuracy of 2COVID : 100.0000 %\n","\n","Accuracy on the ALL val images: 96.4591 %\n","Best model name : ./Checkpoint/model-0.83-best_train_acc.pth\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Test\n","\n","\n","> 可以在此增加其他常見的評估指標(F1、AUC...)\n","\n"],"metadata":{"id":"V4IXH0dPRRKK"}},{"cell_type":"code","source":["import torch\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","CUDA_DEVICES = 0\n","PATH_TO_WEIGHTS = '/content/Checkpoint/model-0.83-best_train_acc.pth' # Your model name\n","\n","\n","def test():\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","    testset = CovidCT(\"/content/input/\", \"test\", data_transform)\n","    test_dl = DataLoader(testset, batch_size=7, shuffle=False, pin_memory=True, num_workers=3)\n","    classes = ['1NonCOVID','2COVID']\n","\n","    # Load model\n","    model = torch.load(PATH_TO_WEIGHTS)\n","    model = model.cuda(CUDA_DEVICES)\n","    model.eval()\n","    \n","    total_correct = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(test_dl):\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            \n","            # batch size\n","            for i in range(labels.size(0)):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","    \n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (\n","        c, 100 * class_correct[i] / class_total[i]))\n","\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","      % (100 * total_correct / total))\n","\n","if __name__ == '__main__':\n","    test()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8BsDK1DVgLx","outputId":"c242b5e2-9fa5-440d-9f23-e17962cc9b17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 792/792 [00:33<00:00, 23.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy of 1NonCOVID :  95.7831 %\n","Accuracy of 2COVID :  67.2591 %\n","\n","Accuracy on the ALL test images: 75.8030 %\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}